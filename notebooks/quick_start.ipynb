{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start: using Jack models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Note: these commands need to be run in terminal from the root of Jack.\n",
    "\n",
    "Download GloVe vectors:\n",
    "> `sh data/GloVe/download.sh`\n",
    "\n",
    "Download pretrained FastQA and DAM models:\n",
    "> `wget -O fastqa.zip https://www.dropbox.com/s/qb796uljoqj0lvo/fastqa.zip?dl=1`\n",
    "\n",
    "> `wget -O dam.zip http://data.neuralnoise.com/jack/natural_language_inference/dam.zip`\n",
    "\n",
    "Prepare the model for use:\n",
    "> `unzip fastqa.zip`\n",
    "\n",
    "> `unzip dam.zip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the imports sorted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('..')    # change dir to Jack root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jack import readers\n",
    "from jack.core import QASetting\n",
    "from jack.io.load import load_jack\n",
    "from notebooks.prettyprint import QAPrettyPrint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecase: QA \n",
    "\n",
    "Load the (previously downloaded) pretrained FastQA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./fastqa/model_module\n"
     ]
    }
   ],
   "source": [
    "fastqa_reader = readers.reader_from_file(\"./fastqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a reading comprehension paragraph and a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. \n",
    "At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\"\"\"\n",
    "\n",
    "question = \"To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge them into a single `QASetting` data structure. This structure requires a question and a list of supporting documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_setting = QASetting(question=question, support=[paragraph])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed the `qa_setting` (paragraph and the question) structure into the reader to get the answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = fastqa_reader([qa_setting])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer can be found here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saint Bernadette Soubirous'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...together with the answer span, which we use to highlight the answer in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to <span style=\"background-color: #ff00ff; color: white\">Saint Bernadette Soubirous</span> in 1858. <br>At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary."
      ],
      "text/plain": [
       "<notebooks.prettyprint.QAPrettyPrint at 0x1f40fd668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QAPrettyPrint(paragraph, answers[0][0].span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the score of the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.591003"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0][0].score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecase: Natural Language Inference (NLI) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load a pretrained DAM [[1]](#ref1) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./dam/model_module\n"
     ]
    }
   ],
   "source": [
    "dam_reader = readers.reader_from_file(\"./dam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and next some Natural Language Inference examples from the SNLI corpus [[2]](#ref2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = \"A boy is jumping on skateboard in the middle of a red bridge.\"\n",
    "hypothesis = \"The boy does a skateboarding trick.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NLI case, the answer is a label among \"entailment\", \"neutral\", and \"contradiction\".\n",
    "\n",
    "We can again use the same data structure `QASetting` as above to feed Jack entailment data. Let's define a new input example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = \"A wedding party is taking pictures.\"\n",
    "hypothesis1 = \"A group of people is celebrating.\"\n",
    "snli_setting1 = QASetting(question=hypothesis1, support=[premise])\n",
    "\n",
    "hypothesis2 = \"A rock band is giving a concert.\"\n",
    "snli_setting2 = QASetting(question=hypothesis2, support=[premise])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate preditions by calling the reader with these inp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entailment \t A wedding party is taking pictures. A group of people is celebrating.\n",
      "contradiction \t A wedding party is taking pictures. A rock band is giving a concert.\n"
     ]
    }
   ],
   "source": [
    "prediction = dam_reader([snli_setting1])\n",
    "print(prediction[0][0].text, \"\\t\", premise, hypothesis1, )\n",
    "\n",
    "prediction = dam_reader([snli_setting2])\n",
    "print(prediction[0][0].text, \"\\t\", premise, hypothesis2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can again also inspect the highest scoring prediction and its score:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id='ref1'>[1]</a> Ankur Parikh, Oscar Täckström, Dipanjan Das, Jakob Uszkoreit . <a href='http://www.aclweb.org/anthology/D14-1162'>\"A Decomposable Attention Model for Natural Language Inference.\"</a> Proceedings of the 2016 conference on empirical methods in natural language processing (EMNLP). 2016. \n",
    "\n",
    "<a id='ref2'>[2]</a> Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning . A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2015."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jack",
   "language": "python",
   "name": "jack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
