{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training with Jack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Note: this command need to be run in terminal from the root of Jack.\n",
    "\n",
    "Download GloVe:\n",
    "> `source data/GloVe/download_small.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.chdir('..')    # change dir to Jack root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jack import readers\n",
    "from jack.core import SharedResources\n",
    "from jack.io.embeddings.embeddings import load_embeddings\n",
    "from jack.io.load import load_jack\n",
    "from jack.util.hooks import LossHook, ExamplesPerSecHook\n",
    "from jack.util.vocab import Vocab\n",
    "from notebooks.prettyprint import QAPrettyPrint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check all the currently available readers from `readers.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the extractive question answering readers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[r for r in readers.extractive_qa_readers.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...the classification readers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[r for r in readers.classification_readers.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the link prediction readers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[r for r in readers.link_prediction_readers.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the reader, we need to define a vocabulary. Additionally, our readers we will need word embeddings too. We'll use the downloaded GloVe [[1]](#ref1) embeddings. Both the vocabulary and the embeddings are shared between the two presented readers in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'data/GloVe/glove.6B.50d.txt'\n",
    "embeddings = load_embeddings(glove_path,\n",
    "                             type='glove')\n",
    "vocab = Vocab(emb=embeddings,\n",
    "              init_from_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastQA (SQuAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training a FastQA [[2]](#ref2) model on a very small subset of the SQuAD dataset [[3]](#ref3), due to slow training. If you want to train your models on a large datasets (like the full SQuAD dataset), we recommend training them on GPUs.\n",
    "\n",
    "Additionally, please note a simpler way to train your models from the command line:\n",
    "\n",
    "> `python3 bin/jack-train.py with config='./conf/qa/squad/fastqa.yaml'`\n",
    "\n",
    "For more details on training from command line, check [README.md](https://github.com/uclmr/jack#quickstart-examples---training-and-usage-of-a-question-answering-system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_path = 'data/SQuAD/snippet.jtr.json'\n",
    "fastqa_train_data = load_jack(squad_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define the hyperparameter values (representation dimensionality, input representation dimensionality, etc.) and general configuration parameters (maximum span size, etc.) for the FastQA reader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_config = {\"repr_dim\": 10,\n",
    "                 \"repr_dim_input\": embeddings.lookup.shape[1],\n",
    "                 \"max_span_size\": 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an example reader, based on the (previously defined) vocabulary and the reader configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_svac = SharedResources(vocab, fastqa_config)\n",
    "fastqa_reader = readers.fastqa_reader(fastqa_svac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, we set up modules (input, model, output) given a training dataset. `is_training` set to `True` indicates we are in the training phase. After this call, all the parameters of the model will be initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_reader.setup_from_data(fastqa_train_data, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the untrained reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is initialised, but has not been trained yet. We can see that from the predictions it makes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [q for q, a in fastqa_train_data]\n",
    "for q, a in zip(questions[:5], fastqa_reader(questions)[:5]):\n",
    "    print(\"Question: \" + q.question)\n",
    "    print(\"Answer:   %s \\t %.3f\" % (a[0].text, a[0].score))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the output is not correct because the model was not trained at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up everything necessary for training. In this case we set the `batch_size` to the size of the dataset, as we're working on a very small dataset. We define hooks which will print out useful information during training (loss and speed) and define the optimiser used (Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we use the bin/jack-train.py script.\n",
    "batch_size = len(fastqa_train_data)\n",
    "# short explanation\n",
    "hooks = [LossHook(fastqa_reader, iter_interval=1), \n",
    "         ExamplesPerSecHook(fastqa_reader, batch_size, iter_interval=1)]\n",
    "optimizer = tf.train.AdamOptimizer(0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and we start the training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_reader.train(optimizer,\n",
    "                    batch_size=batch_size,\n",
    "                    hooks=hooks,\n",
    "                    max_epochs=20,\n",
    "                    training_set=fastqa_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from the trained reader\n",
    "\n",
    "Let's take a look at the predictions after 20 epochs of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fastqa_reader(questions)\n",
    "for q, a in zip(questions[:5], predictions[:5]):\n",
    "    print(\"Question: \" + q.question)\n",
    "    print(\"Answer:   %s \\t (score: %.3f)\\n\" % (a[0].text, a[0].score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's take a look at one of the answers in the context of the paragraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[20].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QAPrettyPrint(questions[20].support[0], predictions[20][0].span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted answers look much better now. However, be aware that this is the prediction of a model trained on a very small subset of data, applied to that same data. Feel free to train your model on the full SQuAD dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "We can now save the model after training it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_reader.store(\"/tmp/fastqa_reader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposable attention model (SNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "\n",
    "We load the data, and prepare it for later printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_path = 'data/SNLI/snippet.jtr_v1.json'\n",
    "snli_train_data = load_jack(snli_path)\n",
    "\n",
    "hypotheses = []\n",
    "premises = []\n",
    "labels = []\n",
    "for input_, output_ in snli_train_data:\n",
    "    premises.append(input_.support[0])\n",
    "    hypotheses.append(input_.question)\n",
    "    labels.append(output_[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reset the tensorflow graph to clear out the previously built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the reader\n",
    "\n",
    "As before, we set up the configuration for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_config = {\"repr_dim\": 10,\n",
    "               \"repr_dim_input\": embeddings.lookup.shape[1],\n",
    "               \"model\": \"dam_snli_reader\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...create the shared resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_svac = SharedResources(vocab, snli_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...build the reader, and set it up with the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_reader = readers.readers[\"dam_snli_reader\"](snli_svac)\n",
    "snli_reader.setup_from_data(snli_train_data, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the training procedure, similarly to the FastQA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(snli_train_data)\n",
    "hooks = [LossHook(snli_reader, iter_interval=1), \n",
    "         ExamplesPerSecHook(snli_reader, batch_size, iter_interval=1)]\n",
    "optimizer = tf.train.AdamOptimizer(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_reader.train(optimizer,\n",
    "                  batch_size=batch_size,\n",
    "                  hooks=hooks,\n",
    "                  max_epochs=20,\n",
    "                  training_set=snli_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from the trained reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = [qa_setting for qa_setting, answers in snli_train_data]\n",
    "output_ = snli_reader(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p, h, l, o in zip(premises[:5], hypotheses[:5], labels[:5], output_[:5]):\n",
    "    print('Premise: {}'.format(p))\n",
    "    print('Hypothesis: {}'.format(h))\n",
    "    print('Prediction: {} (score: {:.2f})  [Label: {}]\\n'.format(o[0].text, o[0].score, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "<a id='ref1'>[1]</a> Pennington, Jeffrey, Richard Socher, and Christopher Manning. <a href='http://www.aclweb.org/anthology/D14-1162'>\"Glove: Global vectors for word representation.\"</a> Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 2014.\n",
    "\n",
    "<a id='ref2'>[2]</a> Weissenborn, Dirk, Georg Wiese, and Laura Seiffe. <a href='http://www.aclweb.org/anthology/K17-1028'>\"Making neural qa as simple as possible but not simpler.\"</a> Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017). 2017.</a>\n",
    "\n",
    "<a id='ref3'>[3]</a> Rajpurkar, Pranav, et al. <a href='http://www.anthology.aclweb.org/D/D16/D16-1264.pdf'>\"SQuAD: 100,000+ Questions for Machine Comprehension of Text.\"</a> Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2016."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
