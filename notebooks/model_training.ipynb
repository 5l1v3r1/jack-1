{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook to showcasing how we interact with JTReaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Download GloVe\n",
    "> `data/GloVe/download_small.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First change dir to JTR parent\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "from jack.io.embeddings.embeddings import load_embeddings\n",
    "from jack.util.vocab import Vocab\n",
    "from jack.core import SharedResources\n",
    "from jack.io.load import load_jack\n",
    "from jack.readers as readers\n",
    "from jack.util.hooks import LossHook, ExamplesPerSecHook\n",
    "from jack.io.load import load_jack\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of all currently available readers from `readers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastqa_reader, modular_qa_reader, fastqa_reader_torch, dam_snli_reader, cbilstm_nli_reader, modular_nli_reader, distmult_reader, complex_reader, transe_reader\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(readers.readers.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a vocabulary (with embeddings for our fastqa_reader, but this is not always necessary)\n",
    "embeddings = load_embeddings('data/GloVe/glove.6B.50d.txt', 'glove')\n",
    "vocab = Vocab(emb=embeddings,\n",
    "              init_from_embeddings=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastQA (SQuAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_train_data = load_jack('data/SQuAD/snippet.jtr.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "Model configuration\n",
    "+\n",
    "Where to find more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_config = {\"repr_dim\": 10,\n",
    "                 \"repr_dim_input\": embeddings.lookup.shape[1],\n",
    "                 \"max_span_size\": 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an example reader, based on vocabulary and the reader configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastqa_svac = SharedResources(vocab, fastqa_config)\n",
    "fastqa_reader = readers.fastqa_reader(fastqa_svac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Explain what setup form data does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all parameters are initialized after this call\n",
    "fastqa_reader.setup_from_data(fastqa_train_data, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the untrained reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Answer:   legend \t -0.142\n",
      "\n",
      "Question: What is in front of the Notre Dame Main Building?\n",
      "Answer:   legend \t -0.165\n",
      "\n",
      "Question: The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
      "Answer:   legend \t -0.162\n",
      "\n",
      "Question: What is the Grotto at Notre Dame?\n",
      "Answer:   legend \t -0.147\n",
      "\n",
      "Question: What sits on top of the Main Building at Notre Dame?\n",
      "Answer:   legend \t -0.169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take a list of inputs, e.g., from our training data\n",
    "questions = [q for q, a in fastqa_train_data]\n",
    "for q, a in zip(questions[:5], fastqa_reader(questions)[:5]):\n",
    "    print(\"Question: \" + q.question)\n",
    "    print(\"Answer:   %s \\t %.3f\" % (a[0].text, a[0].score))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the output is not correct because the model was not trained at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training we use the bin/jack-train.py script.\n",
    "batch_size = len(fastqa_train_data)\n",
    "# short explanation\n",
    "hooks = [LossHook(fastqa_reader, iter_interval=1), \n",
    "         ExamplesPerSecHook(fastqa_reader, batch_size, iter_interval=1)]\n",
    "optimizer = tf.train.AdamOptimizer(0.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the training itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matko/workspace/jack/venv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:jack.core.reader:Number of parameters: 6341\n",
      "INFO:jack.core.reader:Start training...\n",
      "INFO:jack.util.hooks:Epoch 1\tIter 1\ttrain loss 10.043832778930664\n",
      "INFO:jack.util.hooks:Epoch 2\tIter 2\ttrain loss 10.1898832321167\n",
      "INFO:jack.util.hooks:Epoch 3\tIter 3\ttrain loss 8.506146430969238\n",
      "INFO:jack.util.hooks:Epoch 4\tIter 4\ttrain loss 7.6635918617248535\n",
      "INFO:jack.util.hooks:Epoch 5\tIter 5\ttrain loss 7.650871276855469\n",
      "INFO:jack.util.hooks:Epoch 6\tIter 6\ttrain loss 7.5434746742248535\n",
      "INFO:jack.util.hooks:Epoch 7\tIter 7\ttrain loss 6.123935699462891\n",
      "INFO:jack.util.hooks:Epoch 8\tIter 8\ttrain loss 5.673914432525635\n",
      "INFO:jack.util.hooks:Epoch 9\tIter 9\ttrain loss 5.2398176193237305\n",
      "INFO:jack.util.hooks:Epoch 10\tIter 10\ttrain loss 4.7373881340026855\n",
      "INFO:jack.util.hooks:Epoch 11\tIter 11\ttrain loss 3.9916515350341797\n",
      "INFO:jack.util.hooks:Epoch 12\tIter 12\ttrain loss 3.6511764526367188\n",
      "INFO:jack.util.hooks:Epoch 13\tIter 13\ttrain loss 3.220385789871216\n",
      "INFO:jack.util.hooks:Epoch 14\tIter 14\ttrain loss 4.308287620544434\n",
      "INFO:jack.util.hooks:Epoch 15\tIter 15\ttrain loss 3.3123772144317627\n",
      "INFO:jack.util.hooks:Epoch 16\tIter 16\ttrain loss 3.197277069091797\n",
      "INFO:jack.util.hooks:Epoch 17\tIter 17\ttrain loss 2.989947557449341\n",
      "INFO:jack.util.hooks:Epoch 18\tIter 18\ttrain loss 2.58687162399292\n",
      "INFO:jack.util.hooks:Epoch 19\tIter 19\ttrain loss 2.070812225341797\n",
      "INFO:jack.util.hooks:Epoch 20\tIter 20\ttrain loss 1.828403115272522\n"
     ]
    }
   ],
   "source": [
    "fastqa_reader.train(optimizer,\n",
    "                    batch_size=batch_size,\n",
    "                    hooks=hooks,\n",
    "                    max_epochs=20,\n",
    "                    training_set=fastqa_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from the trained reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Answer:   a copper statue of Christ \t (score: -0.888)\n",
      "\n",
      "Question: What is in front of the Notre Dame Main Building?\n",
      "Answer:   a copper statue of Christ \t (score: -0.709)\n",
      "\n",
      "Question: The Basilica of the Sacred heart at Notre Dame is beside to which structure?\n",
      "Answer:   a copper statue of Christ \t (score: -0.985)\n",
      "\n",
      "Question: What is the Grotto at Notre Dame?\n",
      "Answer:   a copper statue of Christ \t (score: -0.987)\n",
      "\n",
      "Question: What sits on top of the Main Building at Notre Dame?\n",
      "Answer:   a copper statue of Christ \t (score: -0.912)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After training the output should look better\n",
    "for q, a in zip(questions[:5], fastqa_reader(questions)[:5]):\n",
    "    print(\"Question: \" + q.question)\n",
    "    print(\"Answer:   %s \\t (score: %.3f)\\n\" % (a[0].text, a[0].score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving into the dir ()\n",
    "fastqa_reader.store(\"/tmp/fastqa_reader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposable attention model (SNLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_train_data = load_jack('data/SNLI/snippet.jtr_v1.json')\n",
    "\n",
    "hypotheses = []\n",
    "premises = []\n",
    "labels = []\n",
    "for input_, output_ in snli_train_data:\n",
    "    premises.append(input_.support[0])\n",
    "    hypotheses.append(input_.question)\n",
    "    labels.append(output_[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_config = {\"repr_dim\": 10,\n",
    "               \"repr_dim_input\": embeddings.lookup.shape[1],\n",
    "               \"model\": \"dam_snli_reader\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create example reader\n",
    "snli_svac = SharedResources(vocab, snli_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:jack.readers.natural_language_inference.decomposable_attention:Building the Attend graph ..\n",
      "INFO:jack.readers.natural_language_inference.decomposable_attention:Building the Compare graph ..\n",
      "INFO:jack.readers.natural_language_inference.decomposable_attention:Building the Aggregate graph ..\n"
     ]
    }
   ],
   "source": [
    "# for training we use the bin/jack-train.py script.\n",
    "# print(\"\\x1b[31m\\\"red\\\"\\x1b[0m\")However, programatically we could quickly train a model like this\n",
    "\n",
    "# setup reader ini training mode\n",
    "tf.reset_default_graph()\n",
    "snli_reader = readers.readers[\"dam_snli_reader\"](snli_svac)\n",
    "snli_reader.setup_from_data(snli_train_data, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = len(snli_train_data)\n",
    "hooks = [LossHook(snli_reader, iter_interval=1), \n",
    "         ExamplesPerSecHook(snli_reader, batch_size, iter_interval=1)]\n",
    "optimizer = tf.train.AdamOptimizer(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:jack.core.reader:Preparing training data...\n",
      "INFO:jack.core.input_module:OnlineInputModule pre-processes data on-the-fly in first epoch and caches results for subsequent epochs! That means, first epoch might be slower.\n",
      "INFO:jack.core.reader:Number of parameters: 20001443\n",
      "INFO:jack.core.reader:Start training...\n",
      "INFO:jack.util.hooks:Epoch 1\tIter 1\ttrain loss 1.0986123085021973\n",
      "INFO:jack.util.hooks:Epoch 2\tIter 2\ttrain loss 1.0929327011108398\n",
      "INFO:jack.util.hooks:Epoch 3\tIter 3\ttrain loss 1.0885658264160156\n",
      "INFO:jack.util.hooks:Epoch 4\tIter 4\ttrain loss 1.0846277475357056\n",
      "INFO:jack.util.hooks:Epoch 5\tIter 5\ttrain loss 1.0950920581817627\n",
      "INFO:jack.util.hooks:Epoch 6\tIter 6\ttrain loss 1.073133111000061\n",
      "INFO:jack.util.hooks:Epoch 7\tIter 7\ttrain loss 1.063262701034546\n",
      "INFO:jack.util.hooks:Epoch 8\tIter 8\ttrain loss 1.0115700960159302\n",
      "INFO:jack.util.hooks:Epoch 9\tIter 9\ttrain loss 0.9028619527816772\n",
      "INFO:jack.util.hooks:Epoch 10\tIter 10\ttrain loss 0.8432081937789917\n",
      "INFO:jack.util.hooks:Epoch 11\tIter 11\ttrain loss 0.6850593686103821\n",
      "INFO:jack.util.hooks:Epoch 12\tIter 12\ttrain loss 0.656381368637085\n",
      "INFO:jack.util.hooks:Epoch 13\tIter 13\ttrain loss 0.633102536201477\n",
      "INFO:jack.util.hooks:Epoch 14\tIter 14\ttrain loss 0.6164972186088562\n",
      "INFO:jack.util.hooks:Epoch 15\tIter 15\ttrain loss 0.6013072729110718\n",
      "INFO:jack.util.hooks:Epoch 16\tIter 16\ttrain loss 0.5868672132492065\n",
      "INFO:jack.util.hooks:Epoch 17\tIter 17\ttrain loss 0.5732516050338745\n",
      "INFO:jack.util.hooks:Epoch 18\tIter 18\ttrain loss 0.5605277419090271\n",
      "INFO:jack.util.hooks:Epoch 19\tIter 19\ttrain loss 0.5487253665924072\n",
      "INFO:jack.util.hooks:Epoch 20\tIter 20\ttrain loss 0.5378441214561462\n"
     ]
    }
   ],
   "source": [
    "snli_reader.train(optimizer,\n",
    "                  batch_size=batch_size,\n",
    "                  hooks=hooks,\n",
    "                  max_epochs=20,\n",
    "                  training_set=snli_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions from the trained reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = [qa_setting for qa_setting, answers in snli_train_data]\n",
    "output_ = snli_reader(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is training his horse for a competition.\n",
      "Prediction: neutral (score: 36.41)  [Label: neutral]\n",
      "\n",
      "Premise: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is at a diner, ordering an omelette.\n",
      "Prediction: entailment (score: 0.45)  [Label: contradiction]\n",
      "\n",
      "Premise: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is outdoors, on a horse.\n",
      "Prediction: entailment (score: 0.45)  [Label: entailment]\n",
      "\n",
      "Premise: Children smiling and waving at camera\n",
      "Hypothesis: They are smiling at their parents\n",
      "Prediction: neutral (score: 30.91)  [Label: neutral]\n",
      "\n",
      "Premise: Children smiling and waving at camera\n",
      "Hypothesis: There are children present\n",
      "Prediction: entailment (score: 0.45)  [Label: entailment]\n",
      "\n",
      "Premise: Children smiling and waving at camera\n",
      "Hypothesis: The kids are frowning\n",
      "Prediction: entailment (score: 0.45)  [Label: contradiction]\n",
      "\n",
      "Premise: A boy is jumping on skateboard in the middle of a red bridge.\n",
      "Hypothesis: The boy skates down the sidewalk.\n",
      "Prediction: entailment (score: 0.45)  [Label: contradiction]\n",
      "\n",
      "Premise: A boy is jumping on skateboard in the middle of a red bridge.\n",
      "Hypothesis: The boy does a skateboarding trick.\n",
      "Prediction: entailment (score: 0.45)  [Label: entailment]\n",
      "\n",
      "Premise: A boy is jumping on skateboard in the middle of a red bridge.\n",
      "Hypothesis: The boy is wearing safety equipment.\n",
      "Prediction: neutral (score: 25.82)  [Label: neutral]\n",
      "\n",
      "Premise: An older man sits with his orange juice at a small table in a coffee shop while employees in bright colored shirts smile in the background.\n",
      "Hypothesis: An older man drinks his juice as he waits for his daughter to get off work.\n",
      "Prediction: neutral (score: 410.85)  [Label: neutral]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p, h, l, o in zip(premises, hypotheses, labels, output_):\n",
    "    print('Premise: {}'.format(p))\n",
    "    print('Hypothesis: {}'.format(h))\n",
    "    print('Prediction: {} (score: {:.2f})  [Label: {}]\\n'.format(o[0].text, o[0].score, l))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "jack",
   "language": "python",
   "name": "jack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
