{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from quebap.projects.modelF.structs import FrozenIdentifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]]], dtype=float32),\n",
       "  array([ 0.], dtype=float32),\n",
       "  array([[[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]]], dtype=float32)),\n",
       " array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.], dtype=float32))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def tok(string):\n",
    "    return string.split(\" \")\n",
    "\n",
    "statements = [tok(w) for w in [\n",
    "    \"eagle can fly\",\n",
    "    \"eagle is a bird\",\n",
    "    \"bird can fly\",\n",
    "    \"duck can fly\"\n",
    "]]\n",
    "\n",
    "questions = [tok(w) for w in [\n",
    "    \"duck can _\"\n",
    "]]\n",
    "\n",
    "WHITESPACE = '[WS]'\n",
    "words = { word for statement in statements + questions for word in statement }\n",
    "words.add(WHITESPACE)\n",
    "vocab = FrozenIdentifier(words)\n",
    "embeddings = tf.diag(tf.ones(len(vocab)))\n",
    "whitespace_repr = tf.gather(embeddings, vocab[WHITESPACE]) # [repr_dim]\n",
    "cost_for_remainder = 1 - tf.gather(embeddings, vocab['_']) - whitespace_repr\n",
    "\n",
    "def match_and_extract(statement, question):\n",
    "    # statement: [batch_size, max_length, repr_dim]\n",
    "    # questions: [batch_size, max_length, repr_dim]\n",
    "    # result: [batch_size, max_length, repr_dim], [batch_size]\n",
    "    # for each batch, for each token, check if both tokens are identical. If so use WHITESPACE, else keep only statement\n",
    "    logits = tf.reduce_sum(statement * question, 2) #[batch_size, max_length]\n",
    "    match_scores = tf.maximum(tf.minimum(logits,1.0),0.0) # alternatively: sigmoids, look for distance etc.\n",
    "    \n",
    "    expanded_match_scores = tf.expand_dims(match_scores, 2)\n",
    "    whitespace_where_match = whitespace_repr * expanded_match_scores # [batch_size, max_length, repr_dim]\n",
    "    statement_elsewhere = (1.0 - expanded_match_scores) * statement\n",
    "    extraction = whitespace_where_match + statement_elsewhere\n",
    "    question_elsewhere = (1.0 - expanded_match_scores) * question #[batch_size, max_length, repr_dim]\n",
    "    question_leftover = whitespace_where_match + question_elsewhere\n",
    "    costs = tf.reduce_sum(question_leftover * cost_for_remainder, [1,2])\n",
    "    return extraction, costs,question_leftover\n",
    "#     return statement_elsewhere\n",
    "\n",
    "def repr_text_batch(texts):\n",
    "    max_length = max([len(text) for text in texts])\n",
    "    result = [[vocab[text[i]] if i < len(text) else vocab[WHITESPACE] for i in range(0, max_length)] for text in texts]\n",
    "    return result\n",
    "\n",
    "def embed_statements(statements):\n",
    "    return tf.gather(embeddings, statements)\n",
    "        \n",
    "statement_placeholder = tf.placeholder(tf.int32,(None,None))\n",
    "question_placeholder = tf.placeholder(tf.int32, (None,None))\n",
    "\n",
    "extract_result = match_and_extract(embed_statements(statement_placeholder), embed_statements(question_placeholder))\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(whitespace_repr)\n",
    "\n",
    "def to_feed_dict(statements, questions):    \n",
    "    text_repr = repr_text_batch(statements + questions)\n",
    "    statement_repr, question_repr = text_repr[:len(statements)], text_repr[len(statements):]\n",
    "    return {statement_placeholder:statement_repr, question_placeholder: question_repr}\n",
    "\n",
    "sess.run((extract_result,whitespace_repr,cost_for_remainder), \n",
    "         feed_dict=to_feed_dict(statements[3:4], questions[:1]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
