{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\n",
      "foil2.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_entities = 2\n",
    "num_relations = 3\n",
    "emb_dim = 4\n",
    "ent_embeddings = tf.Variable(tf.random_normal([num_entities, emb_dim],stddev=0.1), tf.float32)\n",
    "rel_embeddings = tf.Variable(tf.random_normal([num_relations, emb_dim, emb_dim],stddev=0.1), tf.float32)\n",
    "\n",
    "bool_ent_embeddings = tf.sigmoid(ent_embeddings)\n",
    "parameters = [ent_embeddings,rel_embeddings]\n",
    "\n",
    "def scores(rel_ids, arg1_ids, arg2_ids):\n",
    "    batch_rel_embeddings = tf.gather(rel_embeddings, rel_ids) # [num_facts, emb_dim, emb_dim]\n",
    "    arg1_embeddings = tf.gather(bool_ent_embeddings, arg1_ids)\n",
    "    arg2_embeddings = tf.gather(bool_ent_embeddings, arg2_ids) # [num_facts, 1, emb_dim]\n",
    "    return scores_for_embeddings(batch_rel_embeddings, arg1_embeddings, arg2_embeddings)\n",
    "\n",
    "def scores_for_embeddings(batch_rel_embeddings, arg1_embeddings,arg2_embeddings):\n",
    "    expanded_arg1_embeddings = tf.expand_dims(arg1_embeddings, 2)\n",
    "    expanded_arg2_embeddings = tf.expand_dims(arg2_embeddings, 1)\n",
    "    result = tf.reduce_sum(expanded_arg1_embeddings * batch_rel_embeddings * expanded_arg2_embeddings, [1,2])\n",
    "    return result\n",
    "\n",
    "def log_loss(scores, targets):\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(scores, targets)\n",
    "\n",
    "num_order_2_rules = 2\n",
    "use_linear = True\n",
    "if use_linear:\n",
    "    rule_violators_arg1_raw = tf.Variable(tf.random_uniform([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg2_raw = tf.Variable(tf.random_uniform([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg1 = tf.maximum(0., tf.minimum(1., rule_violators_arg1_raw))\n",
    "    rule_violators_arg2 = tf.maximum(0., tf.minimum(1., rule_violators_arg2_raw))\n",
    "else:\n",
    "    rule_violators_arg1_raw = tf.Variable(tf.random_normal([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg2_raw = tf.Variable(tf.random_normal([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg1 = tf.sigmoid(rule_violators_arg1_raw)\n",
    "    rule_violators_arg2 = tf.sigmoid(rule_violators_arg2_raw)\n",
    "\n",
    "rule_violators = [rule_violators_arg1_raw, rule_violators_arg2_raw]\n",
    "\n",
    "def rule_losses(heads, bodies):\n",
    "    head_embeddings = tf.gather(rel_embeddings, heads) # [num_rules, emb_dim, emb_dim]\n",
    "    body_embeddings = tf.gather(rel_embeddings, bodies) # [num_rules, emb_dim, emb_dim]\n",
    "    rule_head_scores = scores_for_embeddings(head_embeddings,rule_violators_arg1, rule_violators_arg2)\n",
    "    rule_body_scores = scores_for_embeddings(body_embeddings,rule_violators_arg1, rule_violators_arg2)\n",
    "    losses = tf.maximum(0.0, rule_body_scores - rule_head_scores)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "# sess.run(log_loss(scores([0,1],[1,2],[2,3]), [1.,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01249681,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(rule_losses([0,1],[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_learn = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "opt_find = tf.train.AdamOptimizer(learning_rate=1.0)\n",
    "\n",
    "rule_violation_loss = rule_losses([1,2],[0,1])\n",
    "training_loss = log_loss(scores([0],[0],[1]),[1.]) + 100 * rule_violation_loss + \\\n",
    "    0.001 * tf.nn.l2_loss(rel_embeddings) + \\\n",
    "    0.001 * tf.nn.l2_loss(ent_embeddings)\n",
    "\n",
    "opt_find_violation = opt_find.minimize(-rule_violation_loss,var_list=rule_violators)\n",
    "opt_find_parameters = opt_learn.minimize(training_loss, var_list=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate parameters\n",
      "[ 0.72563934  0.72563934]\n",
      "[-0.06332336 -0.1491591   0.31144169]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.73712397  0.73712397]\n",
      "[-0.08528074 -0.19883703  0.45219451]\n",
      "Find Violations\n",
      "[ 0.75440991  0.        ]\n",
      "Estimate parameters\n",
      "[ 0.83022487  0.83022487]\n",
      "[-0.25669122 -0.02310122  0.47937843]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.85765785  0.85765785]\n",
      "[-0.30455074  0.05977622  0.44744927]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.84552252  0.84552252]\n",
      "[-0.28293148  0.07878168  0.39898714]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.8240664  0.8240664]\n",
      "[-0.24439813  0.07693154  0.35198343]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.80353218  0.80353218]\n",
      "[-0.20676219  0.06974072  0.31207442]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.7863273  0.7863273]\n",
      "[-0.1745529   0.06214888  0.27999753]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.77238917  0.77238917]\n",
      "[-0.14793487  0.05547256  0.25482884]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.76108336  0.76108336]\n",
      "[-0.12594725  0.04989794  0.23531279]\n",
      "Find Violations\n",
      "[ 0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.12594725,  0.04989794,  0.23531279], dtype=float32)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "num_outer_epochs = 10\n",
    "num_find_violations_epochs = 10\n",
    "num_training_epochs = 10\n",
    "num_print_out = 1\n",
    "for outer_epoch in range(0,num_outer_epochs):\n",
    "    print(\"Estimate parameters\")\n",
    "    for i in range(0,num_training_epochs):\n",
    "        current_loss,_ = sess.run([training_loss,opt_find_parameters])\n",
    "#         if i % (num_training_epochs // num_print_out) == 0:\n",
    "#             print(current_loss)\n",
    "\n",
    "    print(sess.run(training_loss))\n",
    "    print(sess.run(scores([0,1,2],[0,0,0],[1,1,1])))\n",
    "\n",
    "    print(\"Find Violations\")\n",
    "    sess.run(tf.initialize_variables(rule_violators))\n",
    "    for i in range(0,num_find_violations_epochs):\n",
    "        current_loss,_ = sess.run([rule_violation_loss,opt_find_violation])\n",
    "#         if i % (num_find_violations_epochs // num_print_out) == 0:\n",
    "#             print(current_loss)\n",
    "    print(sess.run(rule_violation_loss))\n",
    "                \n",
    "sess.run(scores([0,1,2],[0,0,0],[1,1,1])) \n",
    "# sess.run(scores([1],[0],[1])) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
