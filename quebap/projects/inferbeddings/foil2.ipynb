{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\n",
      "foil2.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_entities = 2\n",
    "num_relations = 3\n",
    "emb_dim = 4\n",
    "ent_embeddings = tf.Variable(tf.random_normal([num_entities, emb_dim],stddev=0.1), tf.float32)\n",
    "rel_embeddings = tf.Variable(tf.random_normal([num_relations, emb_dim, emb_dim],stddev=0.1), tf.float32)\n",
    "\n",
    "bool_ent_embeddings = tf.sigmoid(ent_embeddings)\n",
    "parameters = [ent_embeddings,rel_embeddings]\n",
    "\n",
    "def scores(rel_ids, arg1_ids, arg2_ids):\n",
    "    batch_rel_embeddings = tf.gather(rel_embeddings, rel_ids) # [num_facts, emb_dim, emb_dim]\n",
    "    arg1_embeddings = tf.gather(bool_ent_embeddings, arg1_ids)\n",
    "    arg2_embeddings = tf.gather(bool_ent_embeddings, arg2_ids) # [num_facts, 1, emb_dim]\n",
    "    return scores_for_embeddings(batch_rel_embeddings, arg1_embeddings, arg2_embeddings)\n",
    "\n",
    "def scores_for_embeddings(batch_rel_embeddings, arg1_embeddings,arg2_embeddings):\n",
    "    expanded_arg1_embeddings = tf.expand_dims(arg1_embeddings, 2)\n",
    "    expanded_arg2_embeddings = tf.expand_dims(arg2_embeddings, 1)\n",
    "    result = tf.reduce_sum(expanded_arg1_embeddings * batch_rel_embeddings * expanded_arg2_embeddings, [1,2])\n",
    "    return result\n",
    "\n",
    "def log_loss(scores, targets):\n",
    "    return tf.nn.sigmoid_cross_entropy_with_logits(scores, targets)\n",
    "\n",
    "num_order_2_rules = 2\n",
    "use_linear = True\n",
    "if use_linear:\n",
    "    rule_violators_arg1_raw = tf.Variable(tf.random_uniform([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg2_raw = tf.Variable(tf.random_uniform([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg1 = tf.maximum(0., tf.minimum(1., rule_violators_arg1_raw))\n",
    "    rule_violators_arg2 = tf.maximum(0., tf.minimum(1., rule_violators_arg2_raw))\n",
    "else:\n",
    "    rule_violators_arg1_raw = tf.Variable(tf.random_normal([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg2_raw = tf.Variable(tf.random_normal([num_order_2_rules, emb_dim]), tf.float32) \n",
    "    rule_violators_arg1 = tf.sigmoid(rule_violators_arg1_raw)\n",
    "    rule_violators_arg2 = tf.sigmoid(rule_violators_arg2_raw)\n",
    "\n",
    "rule_violators = [rule_violators_arg1_raw, rule_violators_arg2_raw]\n",
    "\n",
    "def rule_losses_for_embeddings(head_embeddings, body_embeddings, arg1s, arg2s):\n",
    "    rule_head_scores = scores_for_embeddings(head_embeddings,arg1s, arg2s)\n",
    "    rule_body_scores = scores_for_embeddings(body_embeddings,arg1s, arg2s)\n",
    "    losses = tf.maximum(0.0, rule_body_scores - rule_head_scores)\n",
    "    return losses    \n",
    "\n",
    "def rule_losses_for_relation_indices(heads, bodies, arg1s, arg2s):\n",
    "    head_embeddings = tf.gather(rel_embeddings, heads) # [num_rules, emb_dim, emb_dim]\n",
    "    body_embeddings = tf.gather(rel_embeddings, bodies) # [num_rules, emb_dim, emb_dim]\n",
    "    return rule_losses_for_embeddings(head_embeddings,body_embeddings, arg1s, arg2s)\n",
    "\n",
    "\n",
    "def rule_losses(heads, bodies):\n",
    "    head_embeddings = tf.gather(rel_embeddings, heads) # [num_rules, emb_dim, emb_dim]\n",
    "    body_embeddings = tf.gather(rel_embeddings, bodies) # [num_rules, emb_dim, emb_dim]\n",
    "    rule_head_scores = scores_for_embeddings(head_embeddings,rule_violators_arg1, rule_violators_arg2)\n",
    "    rule_body_scores = scores_for_embeddings(body_embeddings,rule_violators_arg1, rule_violators_arg2)\n",
    "    losses = tf.maximum(0.0, rule_body_scores - rule_head_scores)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "# sess.run(log_loss(scores([0,1],[1,2],[2,3]), [1.,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01249681,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(rule_losses([0,1],[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_learn = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "opt_find = tf.train.AdamOptimizer(learning_rate=1.0)\n",
    "\n",
    "rule_violation_loss = rule_losses([1,2],[0,1])\n",
    "training_loss = log_loss(scores([0],[0],[1]),[1.]) + 100 * rule_violation_loss + \\\n",
    "    0.001 * tf.nn.l2_loss(rel_embeddings) + \\\n",
    "    0.001 * tf.nn.l2_loss(ent_embeddings)\n",
    "\n",
    "opt_find_violation = opt_find.minimize(-rule_violation_loss,var_list=rule_violators)\n",
    "opt_find_parameters = opt_learn.minimize(training_loss, var_list=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate parameters\n",
      "[ 0.71793658  0.71793658]\n",
      "[-0.04860514  0.04639324  0.09288298]\n",
      "Find Violations\n",
      "[ 0.  0.]\n",
      "Estimate parameters\n",
      "[ 0.73711264  0.73711264]\n",
      "[-0.08547477  0.07404413  0.1611322 ]\n",
      "Find Violations\n",
      "[ 0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.08547477,  0.07404413,  0.1611322 ], dtype=float32)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "num_outer_epochs = 2\n",
    "num_find_violations_epochs = 10\n",
    "num_training_epochs = 10\n",
    "num_print_out = 1\n",
    "for outer_epoch in range(0,num_outer_epochs):\n",
    "    print(\"Estimate parameters\")\n",
    "#     sess.run(tf.initialize_variables(parameters))\n",
    "    for i in range(0,num_training_epochs):\n",
    "        current_loss,_ = sess.run([training_loss,opt_find_parameters])\n",
    "#         if i % (num_training_epochs // num_print_out) == 0:\n",
    "#             print(current_loss)\n",
    "\n",
    "    print(sess.run(training_loss))\n",
    "    print(sess.run(scores([0,1,2],[0,0,0],[1,1,1])))\n",
    "\n",
    "    print(\"Find Violations\")\n",
    "    sess.run(tf.initialize_variables(rule_violators))\n",
    "    for i in range(0,num_find_violations_epochs):\n",
    "        current_loss,_ = sess.run([rule_violation_loss,opt_find_violation])\n",
    "#         if i % (num_find_violations_epochs // num_print_out) == 0:\n",
    "#             print(current_loss)\n",
    "    print(sess.run(rule_violation_loss))\n",
    "                \n",
    "sess.run(scores([0,1,2],[0,0,0],[1,1,1])) \n",
    "# sess.run(scores([1],[0],[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_violators(heads, bodies):\n",
    "    r2 = tf.gather(rel_embeddings, heads) # [num_rules, emb_dim, emb_dim]\n",
    "    r1 = tf.gather(rel_embeddings, bodies) # [num_rules, emb_dim, emb_dim]\n",
    "\n",
    "    # first score rows of r1 and r2 according to how much r1 > r2\n",
    "    # row_scores = tf.reduce_sum(r1 - r2, 2)\n",
    "    row_scores = tf.reduce_sum(r1 - r2, 2)\n",
    "    # then choose x_i = 1 if row_scores_i > 0 and 0 otherwise\n",
    "    x = tf.to_float(tf.greater(row_scores,0.0)) # [num_rules, emb_dim]\n",
    "    # now calculate cell_scores = x * (r1 - r2)\n",
    "    cell_scores = tf.reduce_sum(tf.expand_dims(x, 2) * (r1 - r2), 1)\n",
    "    \n",
    "    y = tf.to_float(tf.greater(cell_scores,0.0))\n",
    "    \n",
    "    # choose y_i = 1 if cell_scores_i >0 and 0 otherwise\n",
    "    return x,y\n",
    "\n",
    "def loss_of_violators(heads, bodies):\n",
    "    x,y = find_violators(heads, bodies)\n",
    "    return rule_losses_for_relation_indices(heads, bodies, tf.stop_gradient(x), tf.stop_gradient(y))\n",
    "\n",
    "x,y = find_violators([1,2],[0,1])\n",
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73759103,  0.43164906], dtype=float32)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss_of_violators([1,2],[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_loss = log_loss(scores([0],[0],[1]),[1.]) + 2.0 * loss_of_violators([1,2],[0,1]) + \\\n",
    "    0.0001 * tf.nn.l2_loss(rel_embeddings) + \\\n",
    "    0.0001 * tf.nn.l2_loss(ent_embeddings)\n",
    "    \n",
    "single_train = tf.train.AdamOptimizer(learning_rate=0.1)\n",
    "single_opt_op = single_train.minimize(single_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.43165493  2.27274632]\n",
      "[ 0.14303493 -0.02175618  0.09804691]\n",
      "[ 0.60100579  0.60100579]\n",
      "[ 0.25069693  0.62340432  1.11326444]\n",
      "[ 0.60819048  0.07971212]\n",
      "[ 2.6101048   2.6824801   2.73858786]\n",
      "[ 1.29353094  0.01897261]\n",
      "[ 4.21853638  4.35759449  3.97162986]\n",
      "[ 0.01580044  0.01580044]\n",
      "[ 4.50175571  5.15660763  5.18963909]\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(0, 100):\n",
    "    loss, _ = sess.run([single_loss, single_opt_op])\n",
    "    if i % 20 == 0:\n",
    "        print(loss)\n",
    "        print(sess.run(scores([0,1,2],[0,0,0],[1,1,1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.12305434,  0.61180621,  0.84525263,  0.57117897],\n",
       "        [ 0.02237704,  0.48126772,  0.74624395,  0.7609477 ],\n",
       "        [-0.19832431,  0.09006006,  0.62985599,  0.15388986],\n",
       "        [-0.23875275,  0.23403138,  0.6696493 ,  0.58952498]],\n",
       "\n",
       "       [[ 0.04305562,  0.50943649,  1.57455492,  0.48019275],\n",
       "        [ 0.03090568,  0.69868273,  0.81537569,  0.8588748 ],\n",
       "        [ 0.23774242,  0.30310804, -0.01694611,  0.38308805],\n",
       "        [ 0.2869243 ,  0.57682592,  0.4364711 ,  0.25242233]],\n",
       "\n",
       "       [[ 0.79659474,  0.69662964,  0.80099732,  1.18185186],\n",
       "        [ 0.85103011,  0.74020618,  0.4826456 ,  0.48180294],\n",
       "        [ 0.50055486,  0.52855313,  0.61351705,  0.59767389],\n",
       "        [ 0.54371619,  0.54635024,  0.59884536,  0.45197245]]], dtype=float32)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(rel_embeddings[0:3,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
