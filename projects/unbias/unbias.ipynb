{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from typing import NamedTuple, List, Tuple, Sequence,Mapping\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "def to_tensors(data:Sequence[Mapping[str,float]], targets:Mapping[str,float]):\n",
    "    \"\"\"\n",
    "    Turns dictionaries of instance features and target features into numpy arrays.\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    def to_vector(instance:Mapping[str,float]):\n",
    "        vector = np.ndarray(len(vocab))\n",
    "        for key, value in instance.items():\n",
    "            vector[vocab[key]] = value\n",
    "        return vector\n",
    "        \n",
    "    for instance in data:\n",
    "        for key,value in instance.items():\n",
    "            if key not in vocab:\n",
    "                vocab[key] = len(vocab)\n",
    "    data_vectors = []\n",
    "    for instance in data:\n",
    "        data_vectors.append(to_vector(instance))\n",
    "        \n",
    "    data_matrix = np.stack(data_vectors)\n",
    "    \n",
    "    target_vector = to_vector(targets)\n",
    "\n",
    "    print(data_matrix)\n",
    "    \n",
    "    return data_matrix, target_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_correction_weights(data:Sequence[Mapping[str,float]], targets:Mapping[str,float], \n",
    "                                reg_lambda = 0.0, debug=False):\n",
    "    \"\"\"\n",
    "    Calculates a sequence of instance weights such that the total sum of their features\n",
    "    equals/is close to the target vector.\n",
    "    Args:\n",
    "        data: list of feature vectors in sparse dictionary format\n",
    "        targets: feature vector with target total counts\n",
    "    Returns:\n",
    "        `instance_weights`, `total` where instance_weights is a list of weights corresponding\n",
    "        to the instances in `data` and `total` is the total population vector approximation.\n",
    "    \"\"\"\n",
    "    data_matrix, target_vector = to_tensors(data,targets)\n",
    "    \n",
    "    instance_weights = tf.Variable(initial_value=tf.zeros([len(data)]))\n",
    "    data_placeholder = tf.placeholder(tf.float32, shape=data_matrix.shape)\n",
    "    target_placeholder = tf.placeholder(tf.float32, shape=target_vector.shape)\n",
    "    total = tf.einsum(\"ij,j -> i\", data_placeholder, instance_weights)\n",
    "    target_loss = tf.nn.l2_loss(total - target_placeholder)\n",
    "    regularizer = tf.nn.l2_loss(instance_weights - 1)\n",
    "    total_loss = target_loss + reg_lambda * regularizer\n",
    "\n",
    "    sess = tf.Session()\n",
    "    optimizer = tf.train.AdamOptimizer(0.1)\n",
    "    opt_op = optimizer.minimize(total_loss)\n",
    "    project_nonnegative = tf.assign(instance_weights, tf.maximum(0.0,instance_weights))\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(0,100):\n",
    "        feed_dict = {data_placeholder:data_matrix, \n",
    "              target_placeholder:target_vector}\n",
    "        sess.run(opt_op,feed_dict)\n",
    "        sess.run(project_nonnegative)\n",
    "        result = sess.run({'total':total,\n",
    "              'loss':total_loss, \n",
    "              'regularizer':regularizer, \n",
    "              'weights':instance_weights,\n",
    "              'target':target_placeholder},feed_dict)\n",
    "        if debug:\n",
    "            print(result['loss'])\n",
    "            print(result['weights'])\n",
    "            print(result['total'])\n",
    "    return result['weights'],result['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 0.  1.]]\n",
      "0.806\n",
      "[ 0.09999997  0.09999999]\n",
      "[ 0.19999996  0.09999999]\n",
      "0.565831\n",
      "[ 0.19890024  0.19926944]\n",
      "[ 0.3981697   0.19926944]\n",
      "0.379527\n",
      "[ 0.29551122  0.29710737]\n",
      "[ 0.59261858  0.29710737]\n",
      "0.245664\n",
      "[ 0.38814718  0.39260525]\n",
      "[ 0.78075242  0.39260525]\n",
      "0.160732\n",
      "[ 0.47452283  0.48461699]\n",
      "[ 0.95913982  0.48461699]\n",
      "0.118539\n",
      "[ 0.55177951  0.57176262]\n",
      "[ 1.12354207  0.57176262]\n",
      "0.110016\n",
      "[ 0.61678004  0.65248877]\n",
      "[ 1.26926875  0.65248877]\n",
      "0.123891\n",
      "[ 0.66672748  0.72520626]\n",
      "[ 1.39193368  0.72520626]\n",
      "0.148367\n",
      "[ 0.69988877  0.7884959 ]\n",
      "[ 1.48838472  0.7884959 ]\n",
      "0.17318\n",
      "[ 0.71598929  0.84132487]\n",
      "[ 1.55731416  0.84132487]\n",
      "0.191089\n",
      "[ 0.71605974  0.88319659]\n",
      "[ 1.59925628  0.88319659]\n",
      "0.1983\n",
      "[ 0.70194262  0.91418767]\n",
      "[ 1.61613035  0.91418767]\n",
      "0.194053\n",
      "[ 0.6758008   0.93488008]\n",
      "[ 1.61068082  0.93488008]\n",
      "0.179799\n",
      "[ 0.63980412  0.94623655]\n",
      "[ 1.58604074  0.94623655]\n",
      "0.158329\n",
      "[ 0.59599143  0.94946963]\n",
      "[ 1.54546106  0.94946963]\n",
      "0.133022\n",
      "[ 0.54624265  0.94593447]\n",
      "[ 1.49217713  0.94593447]\n",
      "0.10724\n",
      "[ 0.49230176  0.93705273]\n",
      "[ 1.42935443  0.93705273]\n",
      "0.0838978\n",
      "[ 0.43581405  0.9242627 ]\n",
      "[ 1.36007679  0.9242627 ]\n",
      "0.0651609\n",
      "[ 0.37835768  0.90898478]\n",
      "[ 1.28734243  0.90898478]\n",
      "0.0522749\n",
      "[ 0.32145911  0.89259213]\n",
      "[ 1.21405125  0.89259213]\n",
      "0.0455195\n",
      "[ 0.26658642  0.87637943]\n",
      "[ 1.14296579  0.87637943]\n",
      "0.0442854\n",
      "[ 0.21511942  0.86152631]\n",
      "[ 1.07664573  0.86152631]\n",
      "0.0472681\n",
      "[ 0.16829936  0.84905642]\n",
      "[ 1.0173558   0.84905642]\n",
      "0.0527532\n",
      "[ 0.12716804  0.83979714]\n",
      "[ 0.9669652   0.83979714]\n",
      "0.0589447\n",
      "[ 0.09250882  0.83434641]\n",
      "[ 0.92685521  0.83434641]\n",
      "0.0642754\n",
      "[ 0.06480402  0.83305305]\n",
      "[ 0.89785707  0.83305305]\n",
      "0.0676385\n",
      "[ 0.04421799  0.83601373]\n",
      "[ 0.88023174  0.83601373]\n",
      "0.0685046\n",
      "[ 0.03060794  0.84308642]\n",
      "[ 0.87369436  0.84308642]\n",
      "0.0669155\n",
      "[ 0.02355771  0.85391641]\n",
      "[ 0.87747413  0.85391641]\n",
      "0.0633765\n",
      "[ 0.02242555  0.86797082]\n",
      "[ 0.89039636  0.86797082]\n",
      "0.0586852\n",
      "[ 0.02639745  0.8845771 ]\n",
      "[ 0.91097456  0.8845771 ]\n",
      "0.0537376\n",
      "[ 0.0345398   0.90296239]\n",
      "[ 0.93750221  0.90296239]\n",
      "0.0493488\n",
      "[ 0.04584868  0.92229337]\n",
      "[ 0.96814203  0.92229337]\n",
      "0.0461151\n",
      "[ 0.05929558  0.94171596]\n",
      "[ 1.00101149  0.94171596]\n",
      "0.0443356\n",
      "[ 0.07387014  0.96039492]\n",
      "[ 1.03426504  0.96039492]\n",
      "0.0439972\n",
      "[ 0.08862078  0.97755301]\n",
      "[ 1.06617379  0.97755301]\n",
      "0.0448205\n",
      "[ 0.10269269  0.99250776]\n",
      "[ 1.09520042  0.99250776]\n",
      "0.0463493\n",
      "[ 0.1153619   1.00470424]\n",
      "[ 1.12006617  1.00470424]\n",
      "0.0480646\n",
      "[ 0.12606287  1.01374018]\n",
      "[ 1.13980305  1.01374018]\n",
      "0.0494948\n",
      "[ 0.13440718  1.01938236]\n",
      "[ 1.15378952  1.01938236]\n",
      "0.050303\n",
      "[ 0.14019156  1.02157104]\n",
      "[ 1.1617626   1.02157104]\n",
      "0.0503346\n",
      "[ 0.14339474  1.02041483]\n",
      "[ 1.16380954  1.02041483]\n",
      "0.0496209\n",
      "[ 0.14416373  1.01617503]\n",
      "[ 1.16033876  1.01617503]\n",
      "0.0483446\n",
      "[ 0.14279141  1.00924325]\n",
      "[ 1.15203464  1.00924325]\n",
      "0.046779\n",
      "[ 0.13968746  1.00011349]\n",
      "[ 1.13980091  1.00011349]\n",
      "0.0452183\n",
      "[ 0.1353451   0.98935068]\n",
      "[ 1.12469578  0.98935068]\n",
      "0.0439127\n",
      "[ 0.13030536  0.97755831]\n",
      "[ 1.10786366  0.97755831]\n",
      "0.0430233\n",
      "[ 0.12512106  0.96534544]\n",
      "[ 1.0904665   0.96534544]\n",
      "0.0426012\n",
      "[ 0.12032187  0.95329523]\n",
      "[ 1.0736171   0.95329523]\n",
      "0.0425938\n",
      "[ 0.11638251  0.94193602]\n",
      "[ 1.0583185   0.94193602]\n",
      "0.0428724\n",
      "[ 0.11369555  0.9317165 ]\n",
      "[ 1.04541206  0.9317165 ]\n",
      "0.0432719\n",
      "[ 0.11255055  0.92298627]\n",
      "[ 1.03553677  0.92298627]\n",
      "0.0436336\n",
      "[ 0.1131207   0.91598314]\n",
      "[ 1.02910388  0.91598314]\n",
      "0.0438397\n",
      "[ 0.11545759  0.91082752]\n",
      "[ 1.02628517  0.91082752]\n",
      "0.043833\n",
      "[ 0.11949403  0.90752441]\n",
      "[ 1.02701843  0.90752441]\n",
      "0.0436205\n",
      "[ 0.12505433  0.90597218]\n",
      "[ 1.03102648  0.90597218]\n",
      "0.0432608\n",
      "[ 0.13187085  0.90597743]\n",
      "[ 1.03784823  0.90597743]\n",
      "0.0428417\n",
      "[ 0.1396053   0.90727425]\n",
      "[ 1.04687953  0.90727425]\n",
      "0.0424545\n",
      "[ 0.14787327  0.90954655]\n",
      "[ 1.05741978  0.90954655]\n",
      "0.0421709\n",
      "[ 0.15627027  0.91245204]\n",
      "[ 1.06872225  0.91245204]\n",
      "0.0420286\n",
      "[ 0.16439782  0.91564608]\n",
      "[ 1.08004391  0.91564608]\n",
      "0.042027\n",
      "[ 0.17188789  0.91880405]\n",
      "[ 1.09069192  0.91880405]\n",
      "0.0421329\n",
      "[ 0.17842421  0.92164111]\n",
      "[ 1.10006535  0.92164111]\n",
      "0.0422935\n",
      "[ 0.18375939  0.92392778]\n",
      "[ 1.10768723  0.92392778]\n",
      "0.0424522\n",
      "[ 0.18772666  0.92550111]\n",
      "[ 1.11322773  0.92550111]\n",
      "0.0425629\n",
      "[ 0.1902457   0.92627037]\n",
      "[ 1.11651611  0.92627037]\n",
      "0.0425999\n",
      "[ 0.19132251  0.92621762]\n",
      "[ 1.11754012  0.92621762]\n",
      "0.0425607\n",
      "[ 0.19104356  0.9253931 ]\n",
      "[ 1.11643672  0.9253931 ]\n",
      "0.0424627\n",
      "[ 0.18956506  0.92390627]\n",
      "[ 1.11347127  0.92390627]\n",
      "0.0423359\n",
      "[ 0.18709828  0.92191327]\n",
      "[ 1.10901153  0.92191327]\n",
      "0.0422122\n",
      "[ 0.18389222  0.91960198]\n",
      "[ 1.10349417  0.91960198]\n",
      "0.0421178\n",
      "[ 0.18021493  0.91717583]\n",
      "[ 1.09739077  0.91717583]\n",
      "0.0420664\n",
      "[ 0.1763349   0.91483766]\n",
      "[ 1.09117258  0.91483766]\n",
      "0.0420582\n",
      "[ 0.17250364  0.91277432]\n",
      "[ 1.08527792  0.91277432]\n",
      "0.0420822\n",
      "[ 0.16894056  0.91114402]\n",
      "[ 1.08008456  0.91114402]\n",
      "0.0421206\n",
      "[ 0.16582125  0.91006577]\n",
      "[ 1.07588696  0.91006577]\n",
      "0.0421552\n",
      "[ 0.16326958  0.90961313]\n",
      "[ 1.07288265  0.90961313]\n",
      "0.0421723\n",
      "[ 0.16135396  0.90981108]\n",
      "[ 1.07116508  0.90981108]\n",
      "0.0421658\n",
      "[ 0.16008796  0.91063702]\n",
      "[ 1.07072496  0.91063702]\n",
      "0.0421375\n",
      "[ 0.15943471  0.91202521]\n",
      "[ 1.07145989  0.91202521]\n",
      "0.0420956\n",
      "[ 0.15931469  0.91387391]\n",
      "[ 1.07318854  0.91387391]\n",
      "0.042051\n",
      "[ 0.15961599  0.9160549 ]\n",
      "[ 1.07567096  0.9160549 ]\n",
      "0.0420141\n",
      "[ 0.1602062   0.91842449]\n",
      "[ 1.07863069  0.91842449]\n",
      "0.0419916\n",
      "[ 0.1609448   0.92083472]\n",
      "[ 1.08177948  0.92083472]\n",
      "0.0419854\n",
      "[ 0.16169527  0.92314428]\n",
      "[ 1.08483958  0.92314428]\n",
      "0.0419927\n",
      "[ 0.16233584  0.92522842]\n",
      "[ 1.08756423  0.92522842]\n",
      "0.0420078\n",
      "[ 0.16276824  0.92698663]\n",
      "[ 1.08975482  0.92698663]\n",
      "0.0420238\n",
      "[ 0.16292392  0.92834824]\n",
      "[ 1.09127212  0.92834824]\n",
      "0.0420349\n",
      "[ 0.16276738  0.92927539]\n",
      "[ 1.0920428   0.92927539]\n",
      "0.0420381\n",
      "[ 0.16229658  0.9297632 ]\n",
      "[ 1.09205973  0.9297632 ]\n",
      "0.0420332\n",
      "[ 0.16154063  0.92983747]\n",
      "[ 1.09137809  0.92983747]\n",
      "0.0420226\n",
      "[ 0.16055501  0.92955029]\n",
      "[ 1.0901053   0.92955029]\n",
      "0.0420101\n",
      "[ 0.15941501  0.92897385]\n",
      "[ 1.08838892  0.92897385]\n",
      "0.0419992\n",
      "[ 0.15820803  0.92819315]\n",
      "[ 1.08640122  0.92819315]\n",
      "0.0419926\n",
      "[ 0.15702529  0.92729849]\n",
      "[ 1.08432376  0.92729849]\n",
      "0.0419911\n",
      "[ 0.15595391  0.92637777]\n",
      "[ 1.08233166  0.92637777]\n",
      "0.0419937\n",
      "[ 0.15506969  0.92551005]\n",
      "[ 1.08057976  0.92551005]\n",
      "0.0419985\n",
      "[ 0.15443145  0.92475992]\n",
      "[ 1.07919133  0.92475992]\n",
      "0.0420032\n",
      "[ 0.15407705  0.92417389]\n",
      "[ 1.07825089  0.92417389]\n",
      "0.0420057\n",
      "[ 0.15402147  0.92377818]\n",
      "[ 1.07779968  0.92377818]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.15402147,  0.92377818], dtype=float32),\n",
       " array([ 1.07779968,  0.92377818], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{\"ent_premise_China\":1, \"ent_hyp_China\":1},{\"ent_premise_China\":1, \"ent_hyp_China\":0}]\n",
    "targets = {\"ent_premise_China\":1, \"ent_hyp_China\":1}\n",
    "\n",
    "estimate_correction_weights(data, targets, reg_lambda=0.1, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_vector(instance:Mapping[str,float],vocab):\n",
    "    vector = np.ndarray(len(vocab))\n",
    "    for key, value in instance.items():\n",
    "        vector[vocab[key]] = value\n",
    "    return vector\n",
    "\n",
    "def to_sparse_tensors(data:Sequence[Mapping[str,float]], targets:Mapping[str,float]):\n",
    "    \"\"\"\n",
    "    Turns dictionaries of instance features and target features into numpy arrays.\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "\n",
    "        \n",
    "    for instance in data:\n",
    "        for key,value in instance.items():\n",
    "            if key not in vocab:\n",
    "                vocab[key] = len(vocab)\n",
    "                \n",
    "    data_vectors = []\n",
    "    data_indices = []\n",
    "    data_values = []\n",
    "    for instance_nr,instance in enumerate(data):\n",
    "        for key, value in instance.items():\n",
    "            data_indices.append((instance_nr,vocab[key]))\n",
    "            data_values.append(value)\n",
    "        \n",
    "    data_matrix = tf.SparseTensorValue(data_indices, data_values, [len(data),len(vocab)])\n",
    "    \n",
    "    target_vector = to_vector(targets,vocab)\n",
    "\n",
    "    print(data_matrix)\n",
    "    \n",
    "    return data_matrix, target_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_correction_weights_sparse(data:Sequence[Mapping[str,float]], \n",
    "                                       targets:Mapping[str,float], \n",
    "                                       reg_lambda = 0.0, debug=False):\n",
    "    \"\"\"\n",
    "    Calculates a sequence of instance weights such that the total sum of their features\n",
    "    equals/is close to the target vector.\n",
    "    Args:\n",
    "        data: list of feature vectors in sparse dictionary format\n",
    "        targets: feature vector with target total counts\n",
    "    Returns:\n",
    "        `instance_weights`, `total` where instance_weights is a list of weights corresponding\n",
    "        to the instances in `data` and `total` is the total population vector approximation.\n",
    "    \"\"\"\n",
    "    data_matrix, target_vector = to_sparse_tensors(data,targets)\n",
    "    \n",
    "    instance_weights = tf.Variable(initial_value=tf.zeros([len(data),1]))\n",
    "    data_placeholder = tf.sparse_placeholder(tf.float32)\n",
    "    target_placeholder = tf.placeholder(tf.float32, shape=target_vector.shape)\n",
    "    total = tf.sparse_tensor_dense_matmul(data_placeholder,instance_weights,adjoint_a=True)\n",
    "    target_loss = tf.nn.l2_loss(total - target_placeholder)\n",
    "    regularizer = tf.nn.l2_loss(instance_weights - 1)\n",
    "    total_loss = target_loss + reg_lambda * regularizer\n",
    "\n",
    "    sess = tf.Session()\n",
    "    optimizer = tf.train.AdamOptimizer(0.1)\n",
    "    opt_op = optimizer.minimize(total_loss)\n",
    "    project_nonnegative = tf.assign(instance_weights, tf.maximum(0.0,instance_weights))\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(0,100):\n",
    "        feed_dict = {data_placeholder:data_matrix, \n",
    "              target_placeholder:target_vector}\n",
    "        sess.run(opt_op,feed_dict)\n",
    "        sess.run(project_nonnegative)\n",
    "        result = sess.run({'total':total,\n",
    "              'loss':total_loss, \n",
    "              'regularizer':regularizer, \n",
    "              'weights':instance_weights,\n",
    "              'target':target_placeholder},feed_dict)\n",
    "        if debug:\n",
    "            print(result['loss'])\n",
    "            print(result['weights'])\n",
    "            print(result['total'])\n",
    "    return result['weights'],result['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=[(0, 0), (0, 1), (1, 0), (1, 1)], values=[1.0, 1.0, 0.0, 1.0], dense_shape=[2, 2])\n",
      "1.45\n",
      "[[ 0.09999999]\n",
      " [ 0.09999999]]\n",
      "[[ 0.09999999]\n",
      " [ 0.19999997]]\n",
      "1.00353\n",
      "[[ 0.1992512 ]\n",
      " [ 0.19881222]]\n",
      "[[ 0.1992512 ]\n",
      " [ 0.39806342]]\n",
      "0.660505\n",
      "[[ 0.2970311 ]\n",
      " [ 0.29512063]]\n",
      "[[ 0.2970311 ]\n",
      " [ 0.59215176]]\n",
      "0.417828\n",
      "[[ 0.39240062]\n",
      " [ 0.38702989]]\n",
      "[[ 0.39240062]\n",
      " [ 0.77943051]]\n",
      "0.268\n",
      "[[ 0.48417524]\n",
      " [ 0.4719471 ]]\n",
      "[[ 0.48417524]\n",
      " [ 0.95612234]]\n",
      "0.197922\n",
      "[[ 0.57093483]\n",
      " [ 0.54664373]]\n",
      "[[ 0.57093483]\n",
      " [ 1.11757851]]\n",
      "0.188698\n",
      "[[ 0.65109831]\n",
      " [ 0.60767919]]\n",
      "[[ 0.65109831]\n",
      " [ 1.2587775 ]]\n",
      "0.217526\n",
      "[[ 0.72308052]\n",
      " [ 0.65220791]]\n",
      "[[ 0.72308052]\n",
      " [ 1.37528849]]\n",
      "0.261586\n",
      "[[ 0.78551286]\n",
      " [ 0.67879421]]\n",
      "[[ 0.78551286]\n",
      " [ 1.46430707]]\n",
      "0.302194\n",
      "[[ 0.83745778]\n",
      " [ 0.68768436]]\n",
      "[[ 0.83745778]\n",
      " [ 1.52514219]]\n",
      "0.327195\n",
      "[[ 0.87853873]\n",
      " [ 0.68042636]]\n",
      "[[ 0.87853873]\n",
      " [ 1.55896509]]\n",
      "0.331121\n",
      "[[ 0.90895128]\n",
      " [ 0.65923083]]\n",
      "[[ 0.90895128]\n",
      " [ 1.56818211]]\n",
      "0.313943\n",
      "[[ 0.92937672]\n",
      " [ 0.62646067]]\n",
      "[[ 0.92937672]\n",
      " [ 1.55583739]]\n",
      "0.279349\n",
      "[[ 0.94085103]\n",
      " [ 0.58436352]]\n",
      "[[ 0.94085103]\n",
      " [ 1.52521455]]\n",
      "0.233104\n",
      "[[ 0.94463748]\n",
      " [ 0.53498578]]\n",
      "[[ 0.94463748]\n",
      " [ 1.47962332]]\n",
      "0.181693\n",
      "[[ 0.94212562]\n",
      " [ 0.48018175]]\n",
      "[[ 0.94212562]\n",
      " [ 1.42230737]]\n",
      "0.13129\n",
      "[[ 0.93476158]\n",
      " [ 0.42165726]]\n",
      "[[ 0.93476158]\n",
      " [ 1.35641885]]\n",
      "0.0870109\n",
      "[[ 0.9240011 ]\n",
      " [ 0.36101654]]\n",
      "[[ 0.9240011 ]\n",
      " [ 1.28501761]]\n",
      "0.0524232\n",
      "[[ 0.91127491]\n",
      " [ 0.29979619]]\n",
      "[[ 0.91127491]\n",
      " [ 1.21107113]]\n",
      "0.0293015\n",
      "[[ 0.89795667]\n",
      " [ 0.23947954]]\n",
      "[[ 0.89795667]\n",
      " [ 1.13743615]]\n",
      "0.017614\n",
      "[[ 0.88532716]\n",
      " [ 0.18148677]]\n",
      "[[ 0.88532716]\n",
      " [ 1.06681395]]\n",
      "0.0157448\n",
      "[[ 0.87453306]\n",
      " [ 0.12714168]]\n",
      "[[ 0.87453306]\n",
      " [ 1.00167477]]\n",
      "0.0209286\n",
      "[[ 0.86654305]\n",
      " [ 0.07761966]]\n",
      "[[ 0.86654305]\n",
      " [ 0.94416273]]\n",
      "0.0298314\n",
      "[[ 0.86210757]\n",
      " [ 0.03388725]]\n",
      "[[ 0.86210757]\n",
      " [ 0.89599484]]\n",
      "0.0382374\n",
      "[[ 0.86172956]\n",
      " [ 0.        ]]\n",
      "[[ 0.86172956]\n",
      " [ 0.86172956]]\n",
      "0.0361265\n",
      "[[ 0.86560047]\n",
      " [ 0.        ]]\n",
      "[[ 0.86560047]\n",
      " [ 0.86560047]]\n",
      "0.0321301\n",
      "[[ 0.87325197]\n",
      " [ 0.        ]]\n",
      "[[ 0.87325197]\n",
      " [ 0.87325197]]\n",
      "0.0268455\n",
      "[[ 0.88414347]\n",
      " [ 0.        ]]\n",
      "[[ 0.88414347]\n",
      " [ 0.88414347]]\n",
      "0.0209378\n",
      "[[ 0.89768237]\n",
      " [ 0.        ]]\n",
      "[[ 0.89768237]\n",
      " [ 0.89768237]]\n",
      "0.0150535\n",
      "[[ 0.91324323]\n",
      " [ 0.        ]]\n",
      "[[ 0.91324323]\n",
      " [ 0.91324323]]\n",
      "0.00974791\n",
      "[[ 0.93018627]\n",
      " [ 0.        ]]\n",
      "[[ 0.93018627]\n",
      " [ 0.93018627]]\n",
      "0.00543408\n",
      "[[ 0.94787478]\n",
      " [ 0.        ]]\n",
      "[[ 0.94787478]\n",
      " [ 0.94787478]]\n",
      "0.00235407\n",
      "[[ 0.96569204]\n",
      " [ 0.        ]]\n",
      "[[ 0.96569204]\n",
      " [ 0.96569204]]\n",
      "0.000574097\n",
      "[[ 0.9830575]\n",
      " [ 0.       ]]\n",
      "[[ 0.9830575]\n",
      " [ 0.9830575]]\n",
      "6.22637e-07\n",
      "[[ 0.99944204]\n",
      " [ 0.        ]]\n",
      "[[ 0.99944204]\n",
      " [ 0.99944204]]\n",
      "0.00041367\n",
      "[[ 1.01438177]\n",
      " [ 0.        ]]\n",
      "[[ 1.01438177]\n",
      " [ 1.01438177]]\n",
      "0.00151138\n",
      "[[ 1.02748978]\n",
      " [ 0.        ]]\n",
      "[[ 1.02748978]\n",
      " [ 1.02748978]]\n",
      "0.00295923\n",
      "[[ 1.03846574]\n",
      " [ 0.        ]]\n",
      "[[ 1.03846574]\n",
      " [ 1.03846574]]\n",
      "0.00443708\n",
      "[[ 1.04710138]\n",
      " [ 0.        ]]\n",
      "[[ 1.04710138]\n",
      " [ 1.04710138]]\n",
      "0.00567815\n",
      "[[ 1.05328298]\n",
      " [ 0.        ]]\n",
      "[[ 1.05328298]\n",
      " [ 1.05328298]]\n",
      "0.00649578\n",
      "[[ 1.05699027]\n",
      " [ 0.        ]]\n",
      "[[ 1.05699027]\n",
      " [ 1.05699027]]\n",
      "0.00679576\n",
      "[[ 1.05829132]\n",
      " [ 0.        ]]\n",
      "[[ 1.05829132]\n",
      " [ 1.05829132]]\n",
      "0.00657455\n",
      "[[ 1.05733478]\n",
      " [ 0.        ]]\n",
      "[[ 1.05733478]\n",
      " [ 1.05733478]]\n",
      "0.00590546\n",
      "[[ 1.05433905]\n",
      " [ 0.        ]]\n",
      "[[ 1.05433905]\n",
      " [ 1.05433905]]\n",
      "0.00491644\n",
      "[[ 1.04958045]\n",
      " [ 0.        ]]\n",
      "[[ 1.04958045]\n",
      " [ 1.04958045]]\n",
      "0.00376349\n",
      "[[ 1.04337907]\n",
      " [ 0.        ]]\n",
      "[[ 1.04337907]\n",
      " [ 1.04337907]]\n",
      "0.00260422\n",
      "[[ 1.03608477]\n",
      " [ 0.        ]]\n",
      "[[ 1.03608477]\n",
      " [ 1.03608477]]\n",
      "0.001575\n",
      "[[ 1.02806246]\n",
      " [ 0.        ]]\n",
      "[[ 1.02806246]\n",
      " [ 1.02806246]]\n",
      "0.000774428\n",
      "[[ 1.01967776]\n",
      " [ 0.        ]]\n",
      "[[ 1.01967776]\n",
      " [ 1.01967776]]\n",
      "0.000254641\n",
      "[[ 1.01128364]\n",
      " [ 0.        ]]\n",
      "[[ 1.01128364]\n",
      " [ 1.01128364]]\n",
      "2.05785e-05\n",
      "[[ 1.00320768]\n",
      " [ 0.        ]]\n",
      "[[ 1.00320768]\n",
      " [ 1.00320768]]\n",
      "3.62729e-05\n",
      "[[ 0.99574131]\n",
      " [ 0.        ]]\n",
      "[[ 0.99574131]\n",
      " [ 0.99574131]]\n",
      "0.000236279\n",
      "[[ 0.9891308]\n",
      " [ 0.       ]]\n",
      "[[ 0.9891308]\n",
      " [ 0.9891308]]\n",
      "0.00053986\n",
      "[[ 0.98357046]\n",
      " [ 0.        ]]\n",
      "[[ 0.98357046]\n",
      " [ 0.98357046]]\n",
      "0.000865443\n",
      "[[ 0.97919804]\n",
      " [ 0.        ]]\n",
      "[[ 0.97919804]\n",
      " [ 0.97919804]]\n",
      "0.00114309\n",
      "[[ 0.97609299]\n",
      " [ 0.        ]]\n",
      "[[ 0.97609299]\n",
      " [ 0.97609299]]\n",
      "0.00132333\n",
      "[[ 0.97427714]\n",
      " [ 0.        ]]\n",
      "[[ 0.97427714]\n",
      " [ 0.97427714]]\n",
      "0.00138154\n",
      "[[ 0.97371745]\n",
      " [ 0.        ]]\n",
      "[[ 0.97371745]\n",
      " [ 0.97371745]]\n",
      "0.00131777\n",
      "[[ 0.97433126]\n",
      " [ 0.        ]]\n",
      "[[ 0.97433126]\n",
      " [ 0.97433126]]\n",
      "0.00115114\n",
      "[[  9.75993156e-01]\n",
      " [  3.16846526e-05]]\n",
      "[[ 0.97599316]\n",
      " [ 0.97602487]]\n",
      "0.000882602\n",
      "[[  9.78542447e-01]\n",
      " [  9.10654839e-04]]\n",
      "[[ 0.97854245]\n",
      " [ 0.97945309]]\n",
      "0.000581265\n",
      "[[ 0.98177445]\n",
      " [ 0.00244285]]\n",
      "[[ 0.98177445]\n",
      " [ 0.98421729]]\n",
      "0.00031435\n",
      "[[ 0.98545682]\n",
      " [ 0.00440188]]\n",
      "[[ 0.98545682]\n",
      " [ 0.98985869]]\n",
      "0.000130364\n",
      "[[ 0.98934621]\n",
      " [ 0.0065476 ]]\n",
      "[[ 0.98934621]\n",
      " [ 0.99589384]]\n",
      "4.95918e-05\n",
      "[[ 0.99320507]\n",
      " [ 0.00864441]]\n",
      "[[ 0.99320507]\n",
      " [ 1.00184953]]\n",
      "6.33478e-05\n",
      "[[ 0.99681687]\n",
      " [ 0.01047801]]\n",
      "[[ 0.99681687]\n",
      " [ 1.00729489]]\n",
      "0.000140864\n",
      "[[ 0.99999893]\n",
      " [ 0.01186966]]\n",
      "[[ 0.99999893]\n",
      " [ 1.0118686 ]]\n",
      "0.000240894\n",
      "[[ 1.00261247]\n",
      " [ 0.0126869 ]]\n",
      "[[ 1.00261247]\n",
      " [ 1.01529932]]\n",
      "0.000324283\n",
      "[[ 1.00456846]\n",
      " [ 0.01285033]]\n",
      "[[ 1.00456846]\n",
      " [ 1.01741874]]\n",
      "0.000364007\n",
      "[[ 1.00583029]\n",
      " [ 0.01233604]]\n",
      "[[ 1.00583029]\n",
      " [ 1.0181663 ]]\n",
      "0.00035036\n",
      "[[ 1.00641167]\n",
      " [ 0.0111739 ]]\n",
      "[[ 1.00641167]\n",
      " [ 1.01758552]]\n",
      "0.000290694\n",
      "[[ 1.00637221]\n",
      " [ 0.00944196]]\n",
      "[[ 1.00637221]\n",
      " [ 1.01581419]]\n",
      "0.000204481\n",
      "[[ 1.00580895]\n",
      " [ 0.00725767]]\n",
      "[[ 1.00580895]\n",
      " [ 1.01306665]]\n",
      "0.000115901\n",
      "[[ 1.00484645]\n",
      " [ 0.00476672]]\n",
      "[[ 1.00484645]\n",
      " [ 1.00961316]]\n",
      "4.62784e-05\n",
      "[[ 1.00362563]\n",
      " [ 0.00213054]]\n",
      "[[ 1.00362563]\n",
      " [ 1.00575614]]\n",
      "1.05025e-05\n",
      "[[ 1.00229156]\n",
      " [ 0.        ]]\n",
      "[[ 1.00229156]\n",
      " [ 1.00229156]]\n",
      "1.8846e-06\n",
      "[[ 1.00097072]\n",
      " [ 0.        ]]\n",
      "[[ 1.00097072]\n",
      " [ 1.00097072]]\n",
      "1.49828e-07\n",
      "[[ 0.9997263]\n",
      " [ 0.       ]]\n",
      "[[ 0.9997263]\n",
      " [ 0.9997263]]\n",
      "3.85052e-06\n",
      "[[ 0.99861246]\n",
      " [ 0.        ]]\n",
      "[[ 0.99861246]\n",
      " [ 0.99861246]]\n",
      "1.08334e-05\n",
      "[[ 0.99767262]\n",
      " [ 0.        ]]\n",
      "[[ 0.99767262]\n",
      " [ 0.99767262]]\n",
      "1.87511e-05\n",
      "[[ 0.99693805]\n",
      " [ 0.        ]]\n",
      "[[ 0.99693805]\n",
      " [ 0.99693805]]\n",
      "2.55276e-05\n",
      "[[ 0.99642736]\n",
      " [ 0.        ]]\n",
      "[[ 0.99642736]\n",
      " [ 0.99642736]]\n",
      "2.97008e-05\n",
      "[[ 0.99614638]\n",
      " [ 0.        ]]\n",
      "[[ 0.99614638]\n",
      " [ 0.99614638]]\n",
      "3.05921e-05\n",
      "[[ 0.99608898]\n",
      " [ 0.        ]]\n",
      "[[ 0.99608898]\n",
      " [ 0.99608898]]\n",
      "2.83018e-05\n",
      "[[ 0.99623823]\n",
      " [ 0.        ]]\n",
      "[[ 0.99623823]\n",
      " [ 0.99623823]]\n",
      "2.35561e-05\n",
      "[[ 0.99656808]\n",
      " [ 0.        ]]\n",
      "[[ 0.99656808]\n",
      " [ 0.99656808]]\n",
      "1.74586e-05\n",
      "[[ 0.99704546]\n",
      " [ 0.        ]]\n",
      "[[ 0.99704546]\n",
      " [ 0.99704546]]\n",
      "1.11434e-05\n",
      "[[  9.97632444e-01]\n",
      " [  1.42610879e-05]]\n",
      "[[ 0.99763244]\n",
      " [ 0.99764669]]\n",
      "5.43659e-06\n",
      "[[  9.98288274e-01]\n",
      " [  1.28507294e-04]]\n",
      "[[ 0.99828827]\n",
      " [ 0.99841678]]\n",
      "1.59565e-06\n",
      "[[  9.98969257e-01]\n",
      " [  3.00503627e-04]]\n",
      "[[ 0.99896926]\n",
      " [ 0.99926978]]\n",
      "1.49495e-07\n",
      "[[  9.99632657e-01]\n",
      " [  4.88006917e-04]]\n",
      "[[ 0.99963266]\n",
      " [ 1.00012064]]\n",
      "8.53424e-07\n",
      "[[  1.00023973e+00]\n",
      " [  6.52440882e-04]]\n",
      "[[ 1.00023973]\n",
      " [ 1.00089216]]\n",
      "2.88787e-06\n",
      "[[  1.00075865e+00]\n",
      " [  7.61960691e-04]]\n",
      "[[ 1.00075865]\n",
      " [ 1.00152063]]\n",
      "5.2036e-06\n",
      "[[  1.00116658e+00]\n",
      " [  7.93704647e-04]]\n",
      "[[ 1.00116658]\n",
      " [ 1.00196028]]\n",
      "6.87997e-06\n",
      "[[  1.00145042e+00]\n",
      " [  7.35093490e-04]]\n",
      "[[ 1.00145042]\n",
      " [ 1.00218546]]\n",
      "7.38847e-06\n",
      "[[  1.00160766e+00]\n",
      " [  5.84145309e-04]]\n",
      "[[ 1.00160766]\n",
      " [ 1.00219178]]\n",
      "6.6828e-06\n",
      "[[  1.00164521e+00]\n",
      " [  3.48826288e-04]]\n",
      "[[ 1.00164521]\n",
      " [ 1.00199401]]\n",
      "5.12808e-06\n",
      "[[  1.00157833e+00]\n",
      " [  4.55950794e-05]]\n",
      "[[ 1.00157833]\n",
      " [ 1.00162387]]\n",
      "4.08182e-06\n",
      "[[ 1.0014286]\n",
      " [ 0.       ]]\n",
      "[[ 1.0014286]\n",
      " [ 1.0014286]]\n",
      "2.94367e-06\n",
      "[[ 1.00121319]\n",
      " [ 0.        ]]\n",
      "[[ 1.00121319]\n",
      " [ 1.00121319]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.00121319],\n",
       "        [ 0.        ]], dtype=float32), array([[ 1.00121319],\n",
       "        [ 1.00121319]], dtype=float32))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{\"ent_premise_China\":1.0, \"ent_hyp_China\":1.0},{\"ent_premise_China\":1.0, \"ent_hyp_China\":0.0}]\n",
    "targets = {\"ent_premise_China\":1.0, \"ent_hyp_China\":1.0}\n",
    "\n",
    "estimate_correction_weights_sparse(data, targets, reg_lambda=0.0,debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
