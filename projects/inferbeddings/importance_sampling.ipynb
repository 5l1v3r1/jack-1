{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../../..\")\n",
    "import jtr.projects.foil2.sampling as sampling\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preds = 1\n",
    "dim = 5\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([num_preds,dim])) # [num_preds, dim]\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.58681798,  2.11608577,  1.96498656]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "num_samples = 10\n",
    "num_important_samples = 10\n",
    "samples = tf.random_uniform([num_samples, dim], minval=0.0, maxval=1.0) #[num_samples, dim]\n",
    "scores = tf.matmul(weights, samples, transpose_b=True) # [num_preds, num_samples]\n",
    "losses = tf.maximum(scores + 1, 0.0)\n",
    "loss = tf.reduce_mean(losses, 1)\n",
    "\n",
    "is_pos = tf.expand_dims(tf.to_float(tf.greater(weights, 0.0)),1)\n",
    "inverse_transform_u = tf.random_uniform([num_important_samples, dim],minval=0.0001, maxval=0.9999)\n",
    "important_samples = is_pos * tf.sqrt(inverse_transform_u) + (1.0 - is_pos) * (1.0 - tf.sqrt(inverse_transform_u))\n",
    "importance_q_per_dim = is_pos * 2.0 * important_samples + (1.0 - is_pos) * (2.0 - 2.0 * important_samples)\n",
    "importance_q = tf.exp(tf.reduce_sum(tf.log(importance_q_per_dim), 2)) # [num_preds, num_samples]\n",
    "# important samples [num_preds, num_samples, dim]\n",
    "# weights [num_preds, dim]\n",
    "\n",
    "important_scores = tf.reduce_sum(tf.expand_dims(weights,1) * important_samples,2) # tf.matmul(weights, important_samples, transpose_b=True)\n",
    "important_losses = tf.maximum(important_scores + 1, 0.0)\n",
    "important_losses_weighted = important_losses / importance_q\n",
    "important_loss = tf.reduce_mean(important_losses_weighted, 1)\n",
    "\n",
    "# important_samples = \n",
    "\n",
    "sess.run(tf.shape(importance_q_per_dim))\n",
    "sess.run(tf.reduce_sum(tf.log(importance_q_per_dim[0:2,0:3,:]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00393503], dtype=float32),\n",
       " array([[  7.38735437,   2.99969864,  10.04711246,   0.66703683,\n",
       "           9.36897469,   1.31429386,   0.12127773,   5.08102417,\n",
       "           7.59595633,   2.38967776]], dtype=float32),\n",
       " array([[ 0.        ,  0.        ,  0.38925904,  0.        ,  0.0056867 ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ]], dtype=float32),\n",
       " array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.18965346,  0.        ,  0.        ,  0.        ,  0.        ]], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run((important_loss,importance_q,important_losses,losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12127987,\n",
       " array([ 0.01266411], dtype=float32),\n",
       " 0.001440717,\n",
       " 0.98168427,\n",
       " 0.33561617,\n",
       " 0.0092000961,\n",
       " 0.96204323,\n",
       " 0.075913548)"
      ]
     },
     "execution_count": 7,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run((tf.reduce_max(important_losses_weighted),\n",
    "          important_loss, \n",
    "          tf.reduce_min(inverse_transform_u),tf.reduce_max(inverse_transform_u),\n",
    "          tf.reduce_min(importance_q),\n",
    "          tf.reduce_min(important_samples),\n",
    "          tf.reduce_max(important_samples),\n",
    "          tf.reduce_min(importance_q_per_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00048828125"
      ]
     },
     "execution_count": 8,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run(tf.sqrt(2.3841858e-07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.53004754,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45374691,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.50018966,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run(important_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "sess.run(is_pos[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78942645, 1.4846642, 2979.958, 1.0)"
      ]
     },
     "execution_count": 12,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "w_ = 8.0\n",
    "eps = 0.000001\n",
    "f1 = lambda:tf.minimum(w_,-eps)\n",
    "f2 = lambda:tf.maximum(w_,eps)\n",
    "w = tf.case([(tf.less(w_, 0.0),f1)],default=f2)\n",
    "z = (tf.exp(w) - 1.0) \n",
    "u = tf.random_uniform([],0.0,1.0)\n",
    "x = tf.log(z * u + 1) / w\n",
    "p = tf.exp(x * w) * w / z\n",
    "sess.run((x,p,z,tf.sign(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate exponential\n",
    "\n",
    "def sample_exp(w, num_samples):\n",
    "    shape = tf.concat(0,((num_samples,),tf.shape(w)))\n",
    "    f1 = tf.minimum(w,-eps)\n",
    "    f2 = tf.maximum(w,eps)\n",
    "    is_neg = tf.to_float(tf.less(w, 0.0))\n",
    "    w_ = is_neg * f1 + (1.0 - is_neg) * f2\n",
    "    u = tf.random_uniform(shape,0.0,1.0)\n",
    "    z = (tf.exp(w_) - 1.0) \n",
    "    x = tf.log(z * u + 1) / w_\n",
    "#     p = tf.reduce_prod(tf.exp(x * w_) * w_ / z,0)\n",
    "    # TODO: replace with robuster version \n",
    "#     p = tf.exp(tf.reduce_sum(tf.log(tf.exp(x * w_) * w_ / z),1))\n",
    "#     p = tf.exp(tf.reduce_sum(x * w_ + tf.log(w_) - tf.log(z),1))\n",
    "    p = tf.exp(tf.reduce_sum(x * w_ + tf.log(tf.abs(w_)) - tf.log(tf.abs(z)),1))\n",
    "    return x,p\n",
    "\n",
    "def sample_exp_multi(w, num_samples):\n",
    "    # w: [num_rows, dim]\n",
    "    # returns: [num_samples, num_rows, dim] batch of samples drawn from a truncated exponential over [0,1] using w\n",
    "    # as parameter\n",
    "    shape = tf.concat(0,((num_samples,),tf.shape(w))) # [num_samples, num_rows, dim]\n",
    "    f1 = tf.minimum(w,-eps)\n",
    "    f2 = tf.maximum(w,eps)\n",
    "    is_neg = tf.to_float(tf.less(w, 0.0))\n",
    "    w_ = is_neg * f1 + (1.0 - is_neg) * f2\n",
    "    u = tf.random_uniform(shape,0.0,1.0) #[num_samples, num_rows, dim]\n",
    "    z = (tf.exp(w_) - 1.0) # [num_rows, dim]\n",
    "    x = tf.log(z * u + 1) / w_ \n",
    "#     p = tf.reduce_prod(tf.exp(x * w_) * w_ / z,0)\n",
    "    # TODO: replace with robuster version \n",
    "#     p = tf.exp(tf.reduce_sum(tf.log(tf.exp(x * w_) * w_ / z),1))\n",
    "#     p = tf.exp(tf.reduce_sum(x * w_ + tf.log(w_) - tf.log(z),1))\n",
    "    p_components = x * w_ + tf.log(tf.abs(w_)) - tf.log(tf.abs(z))\n",
    "    p = tf.exp(tf.reduce_sum(p_components,2))\n",
    "    return x,p\n",
    "\n",
    "def sample_uniform(w, num_samples):\n",
    "    shape = tf.concat(0,((num_samples,),tf.shape(w)))    \n",
    "    x = tf.random_uniform(shape,0.0,1.0)\n",
    "    return x, tf.constant(1.0)   \n",
    "\n",
    "w = tf.Variable(tf.random_normal([3,10],stddev=0.5)) #[-5.,5.]\n",
    "num_samples_1 = tf.placeholder(shape=[],dtype=tf.int32)# 100\n",
    "num_samples_2 = tf.placeholder(shape=[],dtype=tf.int32)\n",
    "x1,p1 = sampling.random_truncated_exponential(w, num_samples_1)\n",
    "x2,p2 = sample_uniform(w, num_samples_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# sess.run((x1,p1))\n",
    "# sess.run(tf.concat(0, (tf.shape(w),(2,))))\n",
    "# sess.run((x1,p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_by_importance_sampling(w, x, p):\n",
    "    # w = [num_rows, dim]\n",
    "    # x = [num_samples, num_rows, dim]\n",
    "    scores = tf.reduce_sum(w * x, 2) # [num_samples, num_rows]\n",
    "    losses = tf.maximum(scores + 1.0, 0.0)\n",
    "    weighted = losses / p\n",
    "    mean = tf.reduce_mean(weighted, 0) # [num_rows] \n",
    "    return mean\n",
    "    \n",
    "sum_1 = sum_by_importance_sampling(w,x1,p1)\n",
    "sum_2 = sum_by_importance_sampling(w,x2,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.04461384,  0.51943439,  0.66736847], dtype=float32),\n",
       " array([ 1.08322632,  0.46069068,  0.59924716], dtype=float32))"
      ]
     },
     "execution_count": 433,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "# sess.run((sum_1,x1,p1,w,w*x1,tf.reduce_mean((tf.reduce_sum(w*x1,1) + 1.0)/p1)),{num_samples_1:1, num_samples_2:1})\n",
    "sess.run((sum_1,sum_2),{num_samples_1:4, num_samples_2:10000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes must be equal rank, but are 1 and 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, debug_python_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m                                                              \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                                                              status)\n\u001b[0m\u001b[1;32m    595\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    462\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    464\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 1 and 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5276746950d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-88555c8ea79f>\u001b[0m in \u001b[0;36msample_exp\u001b[0;34m(w, num_samples)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msample_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(concat_dim, values, name)\u001b[0m\n\u001b[1;32m    870\u001b[0m   return gen_array_ops._concat(axis=concat_dim,\n\u001b[1;32m    871\u001b[0m                                \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m                                name=name)\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_concat\u001b[0;34m(concat_dim, values, name)\u001b[0m\n\u001b[1;32m    434\u001b[0m   \"\"\"\n\u001b[1;32m    435\u001b[0m   result = _op_def_lib.apply_op(\"Concat\", axis=concat_dim,\n\u001b[0;32m--> 436\u001b[0;31m                                 values=values, name=name)\n\u001b[0m\u001b[1;32m    437\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    747\u001b[0m           op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    748\u001b[0m                            \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                            op_def=op_def)\n\u001b[0m\u001b[1;32m    750\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           return _Restructure(ops.convert_n_to_tensor(outputs),\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2382\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2383\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1781\u001b[0m       raise RuntimeError(\"No shape function registered for standard op: %s\"\n\u001b[1;32m   1782\u001b[0m                          % op.type)\n\u001b[0;32m-> 1783\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1784\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_ConcatShape\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ConcatShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcommon_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors_needed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, input_tensors_needed, debug_python_shape_fn)\u001b[0m\n\u001b[1;32m    594\u001b[0m                                                              status)\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;31m# Convert TensorShapeProto values in output_shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 1 and 0"
     ]
    }
   ],
   "source": [
    "sess.run(sample_exp(5.0, []))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}